{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "import string\n",
    "import nltk\n",
    "import ast\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pymystem3 import Mystem\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCES_PATH = os.path.join(os.pardir, 'resources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/itukh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]     /home/itukh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_ru is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /home/itukh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger_ru')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(RESOURCES_PATH, 'all_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>FinalScore1</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Оригинал взят у в Заложен пятый фрегат проекта...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Бодхисаттва устранения всяческой ущербности (С...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Выпущено два минометных снаряда. Несколько мин...</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>-1</td>\n",
       "      <td>Post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В пригороде Дамаска Джобар во время преследова...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Тема пенсионных реформ оказалась настолько жив...</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Post</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text      Score  FinalScore1  \\\n",
       "0  Оригинал взят у в Заложен пятый фрегат проекта...  [1, 0, 0]            0   \n",
       "1  Бодхисаттва устранения всяческой ущербности (С...        [0]            0   \n",
       "2  Выпущено два минометных снаряда. Несколько мин...       [-1]           -1   \n",
       "3  В пригороде Дамаска Джобар во время преследова...        [0]            0   \n",
       "4  Тема пенсионных реформ оказалась настолько жив...  [0, 0, 0]            0   \n",
       "\n",
       "  Category  \n",
       "0     Post  \n",
       "1     Post  \n",
       "2     Post  \n",
       "3     Post  \n",
       "4     Post  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29442 entries, 0 to 29441\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Text         29442 non-null  object\n",
      " 1   Score        29442 non-null  object\n",
      " 2   FinalScore1  29442 non-null  int64 \n",
      " 3   Category     29442 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 920.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>FinalScore1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Comment</th>\n",
       "      <td>12738</td>\n",
       "      <td>12738</td>\n",
       "      <td>12738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Post</th>\n",
       "      <td>16704</td>\n",
       "      <td>16704</td>\n",
       "      <td>16704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text  Score  FinalScore1\n",
       "Category                           \n",
       "Comment   12738  12738        12738\n",
       "Post      16704  16704        16704"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"Category\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>FinalScore1</th>\n",
       "      <th>Category</th>\n",
       "      <th>! freq</th>\n",
       "      <th>)  freq</th>\n",
       "      <th>:) freq</th>\n",
       "      <th>=) freq</th>\n",
       "      <th>(  freq</th>\n",
       "      <th>:( freq</th>\n",
       "      <th>...</th>\n",
       "      <th>adjectives percent</th>\n",
       "      <th>verbs percent</th>\n",
       "      <th>emotional verbs</th>\n",
       "      <th>obscene words</th>\n",
       "      <th>average word length</th>\n",
       "      <th>exclamation mark count</th>\n",
       "      <th>question mark count</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>average word sentiment</th>\n",
       "      <th>is post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Оригинал взят у в Заложен пятый фрегат проекта...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Post</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.559322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['оригинал', 'взять', 'закладывать', 'пятый', ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Бодхисаттва устранения всяческой ущербности (С...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Post</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128655</td>\n",
       "      <td>0.134503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.725146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['бодхисаттва', 'устранение', 'всяческий', 'ущ...</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Выпущено два минометных снаряда. Несколько мин...</td>\n",
       "      <td>[-1]</td>\n",
       "      <td>-1</td>\n",
       "      <td>Post</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.872727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['выпускать', 'минометный', 'снаряд', 'несколь...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В пригороде Дамаска Джобар во время преследова...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Post</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.885246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['пригород', 'дамаск', 'джобар', 'время', 'пре...</td>\n",
       "      <td>-0.039370</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Тема пенсионных реформ оказалась настолько жив...</td>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>Post</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.087500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['тема', 'пенсионный', 'реформа', 'оказываться...</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text      Score  FinalScore1  \\\n",
       "0  Оригинал взят у в Заложен пятый фрегат проекта...  [1, 0, 0]            0   \n",
       "1  Бодхисаттва устранения всяческой ущербности (С...        [0]            0   \n",
       "2  Выпущено два минометных снаряда. Несколько мин...       [-1]           -1   \n",
       "3  В пригороде Дамаска Джобар во время преследова...        [0]            0   \n",
       "4  Тема пенсионных реформ оказалась настолько жив...  [0, 0, 0]            0   \n",
       "\n",
       "  Category  ! freq  )  freq  :) freq  =) freq  (  freq  :( freq  ...  \\\n",
       "0     Post       0        0        0        0        0        0  ...   \n",
       "1     Post       0        0        0        0        0        0  ...   \n",
       "2     Post       0        0        0        0        0        0  ...   \n",
       "3     Post       0        0        0        0        0        0  ...   \n",
       "4     Post       0        0        0        0        0        0  ...   \n",
       "\n",
       "   adjectives percent  verbs percent emotional verbs obscene words  \\\n",
       "0            0.152542       0.084746               0             0   \n",
       "1            0.128655       0.134503               0             0   \n",
       "2            0.145455       0.090909               0             1   \n",
       "3            0.087432       0.114754               0             2   \n",
       "4            0.075000       0.162500               0             0   \n",
       "\n",
       "   average word length  exclamation mark count  question mark count  \\\n",
       "0             6.559322                       0                    0   \n",
       "1             5.725146                       0                    0   \n",
       "2             5.872727                       0                    0   \n",
       "3             5.885246                       0                    0   \n",
       "4             5.087500                       0                    0   \n",
       "\n",
       "                                              lemmas  average word sentiment  \\\n",
       "0  ['оригинал', 'взять', 'закладывать', 'пятый', ...                0.000000   \n",
       "1  ['бодхисаттва', 'устранение', 'всяческий', 'ущ...                0.020833   \n",
       "2  ['выпускать', 'минометный', 'снаряд', 'несколь...               -0.050000   \n",
       "3  ['пригород', 'дамаск', 'джобар', 'время', 'пре...               -0.039370   \n",
       "4  ['тема', 'пенсионный', 'реформа', 'оказываться...                0.023810   \n",
       "\n",
       "   is post  \n",
       "0     True  \n",
       "1     True  \n",
       "2     True  \n",
       "3     True  \n",
       "4     True  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_path = os.path.join(RESOURCES_PATH, 'processed_data.csv')\n",
    "pd.read_csv(processed_data_path).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obscene_words():\n",
    "    with open(os.path.join(RESOURCES_PATH, 'obscene_words.txt'), 'r') as word_file:\n",
    "        words = word_file.read().replace(',', ' ').lower()\n",
    "        tokens = word_tokenize(words)\n",
    "        obscene = set(tokens)\n",
    "        obscene.remove('на')\n",
    "        obscene.remove('не')\n",
    "        obscene.remove('сила')\n",
    "        return obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emotional_verbs():\n",
    "    emotional_words = pd.read_csv(os.path.join(RESOURCES_PATH, 'verbs_emotional.csv'))\n",
    "    trusted = emotional_words[emotional_words['emotional'] == '+']\n",
    "    return set(trusted['verb'].apply(lambda word: word_tokenize(word.lower())[0]).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_words_sentiment_dictionary():\n",
    "    dictionary_path = os.path.join(RESOURCES_PATH, 'words_all_full_rating_utf_8.csv')\n",
    "    words_sentiment = {}\n",
    "    with open(dictionary_path) as dict_file:\n",
    "        sentiment_reader = csv.DictReader(dict_file, delimiter=';', quotechar='\"')\n",
    "        for sentiment_row in sentiment_reader:\n",
    "            word = sentiment_row['Words']\n",
    "            words_sentiment[word] = float(sentiment_row['average rate'])\n",
    "\n",
    "    return words_sentiment\n",
    "\n",
    "def get_word_sentiment(sentiment_dict, word):\n",
    "    return 0.0 if word not in sentiment_dict else sentiment_dict[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_uppercase_word(text):\n",
    "    for token in text.split(' '):\n",
    "        if token.isupper() and len(token) > 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_pos_percent(pos_predicate, poses):\n",
    "    try:\n",
    "        parsed_poses = ast.literal_eval(poses)\n",
    "    except:\n",
    "        parsed_poses = poses\n",
    "    pos_count = len([1 for p in parsed_poses if pos_predicate(p[1])])\n",
    "    return 1. * pos_count / len(parsed_poses)\n",
    "\n",
    "def get_dictionary_count(poses, dictionary):\n",
    "    try:\n",
    "        parsed_poses = ast.literal_eval(poses)\n",
    "    except:\n",
    "        parsed_poses = poses\n",
    "    return len([1 for p in parsed_poses if p in dictionary])\n",
    "\n",
    "def get_average_word_length(tokens):\n",
    "    try:\n",
    "        parsed_tokens = ast.literal_eval(tokens)\n",
    "    except:\n",
    "        parsed_tokens = tokens\n",
    "    return np.mean(list(map(len, parsed_tokens)))\n",
    "\n",
    "def get_lemmas(text, mystem, stop_words):\n",
    "    # text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    return [token for token in tokens if token not in stop_words and token != \" \"\n",
    "            and token.strip() not in string.punctuation]\n",
    "\n",
    "def get_sentiment(sentiment_dict, lemmas):\n",
    "    try:\n",
    "        parsed_lemmas = ast.literal_eval(lemmas)\n",
    "    except:\n",
    "        parsed_lemmas = lemmas\n",
    "    return np.mean([get_word_sentiment(sentiment_dict, word) for word in parsed_lemmas])\n",
    "\n",
    "class TextualFeaturesExtracter:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.scores = None\n",
    "        self.emotional_verbs = load_emotional_verbs()\n",
    "        self.obscene_words = load_obscene_words()\n",
    "        self.sentiment_dict = load_words_sentiment_dictionary()\n",
    "        self.mystem = Mystem()\n",
    "        self.stop_words = set(stopwords.words(\"russian\"))\n",
    "        self._build_data()\n",
    "        \n",
    "    def _build_data(self):\n",
    "        processed_data_path = os.path.join(RESOURCES_PATH, 'processed_data.csv')\n",
    "        if not os.path.exists(processed_data_path):\n",
    "            self.data['! freq'] = self.data['Text'].apply(lambda x: x.count('!'))\n",
    "\n",
    "            # ':‑\\)' and ':‑\\(' do not appear in the train dataset\n",
    "            for emoticon in ['\\) ', ':\\)', '=\\)', '\\( ', ':\\(', '=\\(']:\n",
    "                emoticon_str = emoticon.replace('\\\\', '')\n",
    "                self.data[f'{emoticon_str} freq'] = self.data['Text'].apply(lambda x: len(re.findall(rf'{emoticon}', x)))\n",
    "\n",
    "            self.data['upper case'] = self.data['Text'].apply(has_uppercase_word)\n",
    "            self.data['tokens'] = self.data['Text'].apply(lambda text: word_tokenize(text.lower()))\n",
    "            self.data['pos'] = self.data['tokens'].apply(lambda tokens: pos_tag(tokens, lang='rus'))\n",
    "            \n",
    "            self.data['lemmas'] = self.data['Text'].apply(\n",
    "                lambda text: get_lemmas(text, self.mystem, self.stop_words))\n",
    "            \n",
    "            self.data['nouns percent'] = self.data['pos'].apply(\n",
    "                lambda poses: get_pos_percent(lambda p: p == 'S', poses))\n",
    "            self.data['adjectives percent'] = self.data['pos'].apply(\n",
    "                lambda poses: get_pos_percent(lambda p: p[0] == 'A' and (len(p) == 1 or p[1] == '='), poses))\n",
    "            self.data['verbs percent'] = self.data['pos'].apply(\n",
    "                lambda poses: get_pos_percent(lambda p: p == 'V', poses))\n",
    "            self.data['exclamation mark count'] = self.data['Text'].apply(\n",
    "                lambda text: text.count('!'))\n",
    "            self.data['question mark count'] = self.data['Text'].apply(\n",
    "                lambda text: text.count('?'))\n",
    "            self.data['emotional verbs'] = self.data['lemmas'].apply(\n",
    "                lambda p: get_dictionary_count(p, self.emotional_verbs))\n",
    "            self.data['obscene words'] = self.data['tokens'].apply(\n",
    "                lambda p: get_dictionary_count(p, self.obscene_words))\n",
    "            self.data['average word length'] = self.data['tokens'].apply(\n",
    "                get_average_word_length)\n",
    "            self.data['average word sentiment'] = self.data['lemmas'].apply(\n",
    "                lambda lemmas: get_sentiment(self.sentiment_dict, lemmas))\n",
    "            self.data['is post'] = self.data['Category'].apply(\n",
    "                lambda c: c == 'Post')\n",
    "\n",
    "            \n",
    "            with open(processed_data_path, 'w') as csv_file:\n",
    "                csv_file.write(self.data.to_csv(index=False))    \n",
    "        \n",
    "        self.processed_data = pd.read_csv(processed_data_path)\n",
    "#         with open(processed_data_path, 'w') as csv_file:\n",
    "#                 csv_file.write(self.processed_data.to_csv(index=False))\n",
    "        \n",
    "        self.scores = self.processed_data['Score'].apply(json.loads)\n",
    "        self.y = self.processed_data['FinalScore1'].to_numpy()\n",
    "        self.X = self.processed_data.copy().drop(columns=['Text', 'FinalScore1', 'Score',\n",
    "                                                         'tokens', 'lemmas', 'pos', 'Category'])\n",
    "    \n",
    "    def get_Xy(self):\n",
    "        return self.X, self.y\n",
    "    \n",
    "    def get_scores(self):\n",
    "        return self.scores\n",
    "    \n",
    "    def get_texts(self):\n",
    "        return self.data['Text'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = TextualFeaturesExtracter(data)\n",
    "X, y = builder.get_Xy()\n",
    "texts = builder.get_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>! freq</th>\n",
       "      <th>)  freq</th>\n",
       "      <th>:) freq</th>\n",
       "      <th>=) freq</th>\n",
       "      <th>(  freq</th>\n",
       "      <th>:( freq</th>\n",
       "      <th>=( freq</th>\n",
       "      <th>upper case</th>\n",
       "      <th>nouns percent</th>\n",
       "      <th>adjectives percent</th>\n",
       "      <th>verbs percent</th>\n",
       "      <th>emotional verbs</th>\n",
       "      <th>obscene words</th>\n",
       "      <th>average word length</th>\n",
       "      <th>exclamation mark count</th>\n",
       "      <th>question mark count</th>\n",
       "      <th>average word sentiment</th>\n",
       "      <th>is post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.152542</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.559322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.257310</td>\n",
       "      <td>0.128655</td>\n",
       "      <td>0.134503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.725146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.872727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.453552</td>\n",
       "      <td>0.087432</td>\n",
       "      <td>0.114754</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.885246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.039370</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.087500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ! freq  )  freq  :) freq  =) freq  (  freq  :( freq  =( freq  upper case  \\\n",
       "0       0        0        0        0        0        0        0        True   \n",
       "1       0        0        0        0        0        0        0       False   \n",
       "2       0        0        0        0        0        0        0       False   \n",
       "3       0        0        0        0        0        0        0        True   \n",
       "4       0        0        0        0        0        0        0       False   \n",
       "\n",
       "   nouns percent  adjectives percent  verbs percent  emotional verbs  \\\n",
       "0       0.389831            0.152542       0.084746                0   \n",
       "1       0.257310            0.128655       0.134503                0   \n",
       "2       0.400000            0.145455       0.090909                0   \n",
       "3       0.453552            0.087432       0.114754                0   \n",
       "4       0.175000            0.075000       0.162500                0   \n",
       "\n",
       "   obscene words  average word length  exclamation mark count  \\\n",
       "0              0             6.559322                       0   \n",
       "1              0             5.725146                       0   \n",
       "2              1             5.872727                       0   \n",
       "3              2             5.885246                       0   \n",
       "4              0             5.087500                       0   \n",
       "\n",
       "   question mark count  average word sentiment  is post  \n",
       "0                    0                0.000000     True  \n",
       "1                    0                0.020833     True  \n",
       "2                    0               -0.050000     True  \n",
       "3                    0               -0.039370     True  \n",
       "4                    0                0.023810     True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 23923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, texts_train, texts_test = train_test_split(X, y, texts, test_size=0.2, \n",
    "                                                            shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5878232072347471\n",
      "Train macro F1: 0.4318736251053181\n",
      "Test accuracy: 0.5919510952623536\n",
      "Test macro F1: 0.4327507860941841\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=RANDOM_STATE, max_iter=2000).fit(X_train, y_train)\n",
    "print('Train accuracy:', clf.score(X_train, y_train))\n",
    "print('Train macro F1:', f1_score(y_train, clf.predict(X_train), average='macro'))\n",
    "print('Test accuracy:', clf.score(X_test, y_test))\n",
    "print('Test macro F1:', f1_score(y_test, clf.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Logistic Regression Model + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10, max_df=0.5, max_features=1000)\n",
    "X_texts_train = vectorizer.fit_transform(texts_train)\n",
    "X_texts_test = vectorizer.transform(texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = np.hstack((X_train.to_numpy(), X_texts_train.toarray()))\n",
    "X_test_combined = np.hstack((X_test.to_numpy(), X_texts_test.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6523585105931304\n",
      "Train macro F1: 0.5276122600375901\n",
      "Test accuracy: 0.6130073017490236\n",
      "Test macro F1: 0.4797736508285406\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=RANDOM_STATE, max_iter=2000).fit(X_train_combined, y_train)\n",
    "print('Train accuracy:', clf.score(X_train_combined, y_train))\n",
    "print('Train macro F1:', f1_score(y_train, clf.predict(X_train_combined), average='macro'))\n",
    "print('Test accuracy:', clf.score(X_test_combined, y_test))\n",
    "print('Test macro F1:', f1_score(y_test, clf.predict(X_test_combined), average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
